\newpage
\section{Experiments}

% \section{Baseline}

We compare our model to the vanilla logistic regression algorithm by implementing both using the TensorFlow library. Both the models can perform multi-class and multi-label classification. For multi-class, we use the softmax function to assign probabilities to each class which add up to 1. We use the sigmoid function for multi-label classification to train an independent logistic regression model for each class and accept all labels greater than a certain threshold as predictions.

We tune our model using learning rate and regularization parameter as hyper-parameters and train with different number of epochs till the loss converges. For multi-label problems, we also use prediction threshold as one of the hyper-parameters to list labels with probabilities greater than the threshold value.

\subsection{Evaluation}

To evaluate the performance of both models for multi-class problems, we use accuracy and F1 measures.

For multi-label problems, predictions for an instance is a set of labels, and therefore the prediction can be fully correct, partially-correct or fully-incorrect. Thus, to better evaluate our models we will use the following three measures: \textit{set accuracy}, which is the ratio of perfectly matched instances to the total number of instances; \textit{instance-F1}, which evaluates the performance of partially correct predictions averaged over instances; \textit{label-F1}, which evaluates the performance of partially correct predictions averaged over labels.\\

For a dataset with ground truth labels $y^{(n)}$ and predictions $\hat{y}^{(n)}$, and n instances where n = 1,2,...,N, these three measures are defined as:

\begin{alignat}{2}
set\; accuracy & = \frac{1}{N} \sum_{n=1}^{N} {I(y^{(n)} = \hat{y}^{(n)})}\\
instance \mbox{-} F1 & = \frac{1}{N} \sum_{n=1}^{N} \frac{2\sum_{l=1}^{L} {y^{(n)}_{l} \hat{y}^{(n)}_{l}}}{\sum_{l=1}^{L} {y^{(n)}_{l}} + \sum_{l=1}^{L} {\hat{y}^{(n)}_{l}}}
\hspace{6ex}
label \mbox{-} F1 & = \frac{1}{N} \sum_{n=1}^{N} \frac{2\sum_{n=1}^{N} {y^{(n)}_{l} \hat{y}^{(n)}_{l}}}{\sum_{n=1}^{N} {y^{(n)}_{l}} + \sum_{n=1}^{N} {\hat{y}^{(n)}_{l}}}
\end{alignat}

\noindent where for each instance $n$, $y^{(n)}_{l}$ = 1 if label $l$ is a given label in ground truth; \\
$\hat{y}^{(n)}_{l}$ = 1 if label $l$ is a predicted label.
\newpage
\subsection{Datasets}

\subsubsection{IMDb}

The IMDb dataset is created by Meka with movie plot text summaries labelled with genres sourced from the Internet Movie Database Interface. It is a collection of 35,000 documents partitioned across 25 different genres. The task is to assign multiple genres to a movie description.

Below is a list of the 25 different genres with individual genre counts.

\begin{table}[htbp]
\begin{tabular}{ll|ll}
Drama       & 11726 & Family    & 1564 \\
Comedy      & 7279  & Biography & 1151 \\
Romance     & 4488  & War       & 1049 \\
Thriller    & 4468  & Animation & 949  \\
Crime       & 3195  & History   & 932  \\
Action      & 3120  & Music     & 827  \\
Horror      & 2414  & Musical   & 687  \\
Adventure   & 2313  & Western   & 574  \\
Documentary & 1895  & Short     & 546  \\
Mystery     & 1775  & Sport     & 471  \\
Sci-Fi      & 1692  & Film-Noir & 257  \\
Fantasy     & 1612  & News      & 68  
\end{tabular}
\caption{\label{tab:widgets}The 24 topic categories for the IMDb dataset with the number of examples assigned to them.}
\end{table}

\subsubsection{Guardian}

The Guardian is a National British daily newspaper, known until 1959 as the Manchester Guardian. Its online edition was the fifth most widely read in the world as of October 2014, with over 42 million readers. This dataset contains articles on various topics like World news, UK news, Culture, Politics, Media, Business, Society etc.

All the data had been manually scrapped from the Guardian website with each file containing a document and its associated tags. The dataset in use contains 20 different classes and the task is to assign multiple tags to each news article.

Below is a list of the 20 different genres.

\begin{table}[htbp]
\begin{tabular}{l|l}
Blogging       & LGBT rights    \\
Christianity      & Mental health \\
Comedy     & Poetry       \\
Computing    & Premier League \\
Counter-terrorism policy      & Public finance   \\
Drugs      & Public sector cuts     \\
Financial crisis      & Research   \\
Global enonomy   & Restaurants   \\
Health policy & Retail industry     \\
Inequality     & Tax and spending      
\end{tabular}
\caption{\label{tab:widgets}The 20 topic categories for the Guardian dataset with the number of examples assigned to them.}
\end{table}

\newpage
\subsubsection{20 Newsgroups}

The 20 Newsgroups dataset is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. It has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.

The data is organized into 20 different newsgroups, each corresponding to a different topic. Some of the newsgroups are very closely related to each other (e.g.\textbf{ comp.sys.ibm.pc.hardware / comp.sys.mac.hardware}), while others are highly unrelated (e.g \textbf{misc.forsale / soc.religion.christian}). Except for a small fraction of the articles, each document belongs to exactly one newsgroup. The task is to learn which newsgroup an article was posted to. Below is a list of 20 newsgroup partitioned according to their subject matter.\\

\begin{table}[htbp]
\begin{tabular}{|l|l|l|lllllll}
\cline{1-3}
comp.graphics            &                       &                        &  &  &  &  &  &  &  \\
comp.os.ms-windows.misc  & rec.autos             & sci.crypt              &  &  &  &  &  &  &  \\
comp.sys.ibm.pc.hardware & rec.motorcycles       & sci.electronics        &  &  &  &  &  &  &  \\
comp.sys.mac.hardware    & rec.sport.baseball    & sci.med                &  &  &  &  &  &  &  \\
comp.windows.x           & rec.sport.hockey      & sci.space              &  &  &  &  &  &  &  \\ \cline{1-3}
                         & talk.politics.misc    & talk.religion.misc     &  &  &  &  &  &  &  \\
misc.forsale             & talk.politics.guns    & alt.atheism            &  &  &  &  &  &  &  \\
                         & talk.politics.mideast & soc.religion.christian &  &  &  &  &  &  &  \\ \cline{1-3}
\end{tabular}
\caption{\label{tab:widgets}Newsgroups used in newsgroups data}
\end{table}

\newpage
\subsection{Model Performance}

Below is a table showing how our model performed as compared to the pyramid and tensorflow implementation of vanilla logistic regression.

\begin{table}[htbp]
\centering
% \resizebox{\textwidth}{!}{%
\begin{tabular}{l|c|c|c|c}
Datasets & \begin{tabular}[c]{@{}c@{}}Pyramid LR\\ Set Accuracy\end{tabular} & \begin{tabular}[c]{@{}c@{}}Tensorflow LR\\ Set Accuracy\end{tabular} & \begin{tabular}[c]{@{}c@{}}Our model\\ Set Accuracy\end{tabular}\\\hline
IMDb & 19.66 & 18.21 & 20.30\\
20Newsgroup & 55.64 & 55.75 & 58.80\\
Guardian & 59.3 & 53.46 & 59.3\\
\end{tabular}%
% }
\caption{\label{tab:widgets}Set-Accuracy Results.}
\end{table}

\begin{table}[htbp]
\centering
% \resizebox{\textwidth}{!}{%
\begin{tabular}{l|c|c|c|c}
Datasets & \begin{tabular}[c]{@{}c@{}}Pyramid LR\\ Instance-F1\end{tabular} & \begin{tabular}[c]{@{}c@{}}Tensorflow LR\\ Instance-F1\end{tabular} & \begin{tabular}[c]{@{}c@{}}Our model\\ Instance-F1\end{tabular}\\\hline
IMDb & 56.14 & 57.87 & 58.52\\
20Newsgroup & 55.64 & 55.75 & 58.80\\
Guardian & 65.13 & 65.61 & 69.41\\
\end{tabular}%
% }
\caption{\label{tab:widgets}Instance-F1 Results.}
\end{table}

\noindent We also run a validation experiment with artificially modified dataset 20newsgroup to mimic sparse representation: we found the most similar words in the train set with cosine similarity greater than 0.3 and make the feature values of all but one of the words equal to zero. We then compared the performance of our model with logistic regression before and after zeroing feature values of similar words. The below results show that our model was able to get a good test accuracy after the imposed sparsity.\\


\begin{tabular}{l|c|c}
\hline
					& Logistic Regression 	& Our model \\
Before zeroing features		& 82.6			& 84.01 \\
After zeroing features		& 75.67			& 83.54\\
\hline
\end{tabular}